# ğŸ’¡ Self-Service Analytics: Natural Language to SQL + Visualization

A self-service analytics web app that enables business stakeholders to generate SQL queries and visualizations simply by typing natural language. This app uses the **Olist e-commerce dataset from Kaggle stored in a MySQL database**, The app is powered by a Groq LLM API for query generation, NL4DV for data-to-visual insight mapping, and Streamlit for an intuitive user interface.


## ğŸ“Œ Key Features

- ğŸ—£ï¸ Translate natural language prompts into SQL queries using the Groq API
- ğŸ§® Execute SQL queries on a MySQL database (`olist_data`)
- ğŸ“Š Automatically visualize results with Altair charts
- ğŸ§™ğŸ» Enable non-technical users to explore data without writing code
- ğŸ” Reusable, fast, and no-code interface


## ğŸ”§ Tech Stack

- **Frontend**: Streamlit
- **Backend**: Python, MySQL
- **NLP-to-SQL**: Groq API
- **Natural Language â†’ Visualization Mapping**: NL4DV, Stanford CoreNLP
- **Visualization**: Altair


## ğŸ–¨ï¸   Flyer

[Flyer.pdf](Flyer.pdf)


## ğŸ¥ Demo
ğŸ“½ï¸ [Click here to watch the demo video](demo1.mp4)


## ğŸš€ Run Locally

### 1. Install dependencies

```bash
pip install -r requirements.txt
```
### 2. Setup Stanford NLP Parser

Due to file size limits, JAR files are not included in this repository. Please download the following files manually:

- [`stanford-parser-3.9.2-models.jar`](https://nlp.stanford.edu/software/lex-parser.shtml)
- [`stanford-english-corenlp-2018-10-05-models.jar`](https://stanfordnlp.github.io/CoreNLP/)

Place them in the `parsers/` folder like this:

### 3. Set up MySQL database
Ensure a MySQL instance is running with the olist_data database and your credentials.

### 4. Configure connection
Copy the example config and fill in your info:
```bash
cp config/db_connect.json.example db_connect.json
```

### 5. Run the app
```bash
streamlit run app/main_app.py
```


## ğŸ‘©â€ğŸ’» Team
Yen-Hsi Kuo, Sam Neal, Ruth Hsu, Maggie Wang, Rachel Liang
